{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faa69f9-d69f-4dcc-b9ba-4f2fe2a9db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πåpdf\n",
    "import fitz\n",
    "from langchain.docstore.document import Document\n",
    "# ‡∏£‡∏∞‡∏ö‡∏∏path‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£\n",
    "pdf1 = r\"C:\\Users\\Kitti\\OneDrive\\‡πÄ‡∏î‡∏™‡∏Å‡πå‡∏ó‡πá‡∏≠‡∏õ\\‡∏á‡∏≤‡∏ô\\AI Engineer Test\\AI Engineer Test\\ai_test_user_feedback.pdf\"\n",
    "pdf2 = r\"C:\\Users\\Kitti\\OneDrive\\‡πÄ‡∏î‡∏™‡∏Å‡πå‡∏ó‡πá‡∏≠‡∏õ\\‡∏á‡∏≤‡∏ô\\AI Engineer Test\\AI Engineer Test\\ai_test_bug_report.pdf\"\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£texts‡πÑ‡∏ß‡πâ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£\n",
    "texts = []\n",
    "\n",
    "for file_path in [pdf1, pdf2]:\n",
    "    doc = fitz.open(file_path)\n",
    "    for i, page in enumerate(doc): #‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£\n",
    "        content = page.get_text()\n",
    "        if content.strip():\n",
    "            texts.append(Document(\n",
    "                page_content=content,\n",
    "                metadata={\"source\": file_path, \"page\": i + 1}\n",
    "            ))\n",
    "\n",
    "for i, doc in enumerate(texts[:3]):  # ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏î‡∏π3‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏£‡∏Å\n",
    "    print(f\"üîπ Document {i+1}\")\n",
    "    print(f\"Source: {doc.metadata['source']} - Page: {doc.metadata['page']}\") #‡∏î‡∏πmetadata‡∏Ç‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£\n",
    "    print(doc.page_content[:300])  # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ï‡πâ‡∏ô 300 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82eca07-469e-4acc-b346-88e805a62c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load environment\n",
    "load_dotenv(dotenv_path=r\"C:\\Users\\Kitti\\OneDrive\\‡πÄ‡∏î‡∏™‡∏Å‡πå‡∏ó‡πá‡∏≠‡∏õ\\‡∏á‡∏≤‡∏ô\\Hugging Face\\Tokens\\HUGGINGFACE_API_KEY.env\")\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key ‡∏Ç‡∏≠‡∏á Hugging Face\n",
    "HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\") # ‡πÉ‡∏™‡πà‡∏Ñ‡∏µ‡∏¢‡πå API ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà\n",
    "\n",
    "if \"HUGGINGFACE_API_KEY\" in os.environ:\n",
    "    print(\"Environment variable loaded successfully!\")\n",
    "    print(\"HUGGINGFACE_API_KEY:\", os.environ[\"HUGGINGFACE_API_KEY\"])  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤ (‡∏≠‡∏¢‡πà‡∏≤‡πÅ‡∏ä‡∏£‡πå‡∏Ñ‡πà‡∏≤ API Key ‡∏à‡∏£‡∏¥‡∏á)\n",
    "else:\n",
    "    print(\"Failed to load environment variable.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e65bb2f-5a07-4a78-877e-447b450bbbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥embeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥embedding‡∏ú‡πà‡∏≤‡∏ôHuggingFaceEmbeddings\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Åembeddings‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£vector store\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# ‡πÉ‡∏ä‡πâretriever‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Åvector store\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ffac27-727c-4c1f-bb15-8360ba749163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import model LLM ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤\n",
    "import ollama\n",
    "#‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô\n",
    "prompt = \"‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏´‡∏•‡∏ß‡∏á‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡∏Ñ‡∏∑‡∏≠\"\n",
    "\n",
    "response = ollama.chat(model=\"llama3.2\", messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are male. Answer with ‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "])\n",
    "\n",
    "response[\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aa56d1-63e5-4822-9178-3fb650ce7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query_text):\n",
    "     # ‡πÉ‡∏ä‡πâretriever‡∏î‡∏∂‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö query_text\n",
    "     docs = retriever.invoke(query_text)\n",
    "     # ‡∏™‡∏£‡πâ‡∏≤‡∏ácontext‡∏à‡∏≤‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£\n",
    "     context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "     # ‡∏™‡∏£‡πâ‡∏≤‡∏áprompt‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "     prompt = f\"\"\"You are an internal AI assistant that helps the product and engineering team extract \n",
    "     insights from internal documents and team reports. use information from context to answer.\n",
    "     if you can't find information that match to user's question, just say you don't find information.:\\n{context}\\nQuestion: {query_text}\"\"\"\n",
    "     # ‡∏™‡πà‡∏á prompt ‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏• LLaMA ‡∏ú‡πà‡∏≤‡∏ô Ollama\n",
    "     response = ollama.chat(model=\"llama3.2\", messages=[\n",
    "        {\"role\": \"system\", \"content\": \"\"\"You are an assistant that extracts structured insights from documents.\n",
    "        You must always reply with a JSON object like this:\n",
    "     {\n",
    "      \"Feedback #n\": \"...\",\n",
    "     {\"Bug #n\": \n",
    "       Title: \"...\"},\n",
    "     }\n",
    "     \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "     ])\n",
    "\n",
    "     return response[\"message\"][\"content\"]\n",
    "# ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô     \n",
    "print(generate_response(\"What are the issues reported on email notification?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
